{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e3e5811",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import cv2\n",
    "import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "958e785c",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_datapath = r\"C:\\Users\\dgyawa1\\Desktop\\dev\\food_data\"\n",
    "training_datapath = r\"C:\\Users\\dgyawa1\\Desktop\\dev\\yolo_data\"\n",
    "annotation_dir = r\"C:\\Users\\dgyawa1\\Desktop\\dev\\annot_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "215b6394",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(training_datapath):\n",
    "        os.makedirs(training_datapath)\n",
    "\n",
    "i = 0\n",
    "for label in os.listdir(original_datapath):\n",
    "    label_path = os.path.join(original_datapath,label)\n",
    "    for img in os.listdir(label_path):\n",
    "        src_path = os.path.join(label_path,img)\n",
    "        if img.endswith(\".jpg\"):\n",
    "            dest_filename = os.path.splitext(img)[0] + \"_\" + label +\".jpg\"\n",
    "            dest_path = os.path.join(training_datapath,dest_filename)\n",
    "            shutil.copy(src_path,dest_path)\n",
    "        if img.endswith(\".txt\"):\n",
    "            with open(src_path,\"r\") as f:\n",
    "                for line in f.readlines():\n",
    "                    all_line = line.split(\" \") \n",
    "                    all_line_copy = all_line.copy()\n",
    "                    txt_filename = all_line[0] + \"_\" + label +\".txt\"\n",
    "                    img_arr = cv2.imread(os.path.join(label_path,all_line[0]+'.jpg'))\n",
    "                    height,width,_ = img_arr.shape\n",
    "                    all_line[0] = str(i)\n",
    "                    all_line[1] = str(((int(all_line_copy[1]) + int(all_line_copy[3]))/2)/width)\n",
    "                    all_line[2] = str(((int(all_line_copy[2]) + int(all_line_copy[4]))/2)/height)\n",
    "                    all_line[3] = str((int(all_line_copy[3]) - int(all_line_copy[1]))/width)\n",
    "                    all_line[4] = str((int(all_line_copy[4]) - int(all_line_copy[2]))/width)\n",
    "                    txt_destination = os.path.join(training_datapath,txt_filename)\n",
    "                    with open(txt_destination, \"w\") as fname:\n",
    "                        fname.write(\" \".join(all_line))\n",
    "    i = i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7253776f",
   "metadata": {},
   "source": [
    "## Visualize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "14485ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 890/890 [00:10<00:00, 88.42it/s] \n"
     ]
    }
   ],
   "source": [
    "all_images = glob.glob(r\"C:\\Users\\dgyawa1\\Desktop\\dev\\yolo_data\\*.jpg\")\n",
    "\n",
    "label_dict = {\n",
    "    \"0\":\"chicken\",\n",
    "    \"1\": \"fries\",\n",
    "    \"2\": \"lettuce\",\n",
    "    \"3\": \"pizza\",\n",
    "    \"4\": \"roll\"\n",
    "}\n",
    "\n",
    "\n",
    "for file in tqdm(all_images):\n",
    "    img_name = os.path.splitext(os.path.basename(file))[0]\n",
    "    file_name = os.path.join(training_datapath,img_name+\".txt\")\n",
    "    with open(file_name,\"r\") as f:\n",
    "        for i in f.readlines():\n",
    "            all_line = i.split(\" \")\n",
    "            label,x0,y0,x2,y2 = all_line[0], int(all_line[1]), int(all_line[2]), int(all_line[3]), int(all_line[4])\n",
    "            img = cv2.imread(file)\n",
    "#             img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "            cv2.rectangle(img,(x0,y0),(x2,y2),(0,0,255),2)\n",
    "            cv2.putText(img,label_dict[label],(x0+5,y0-5), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,0,0),2)\n",
    "            save_dir = os.path.join(annotation_dir,os.path.basename(file))\n",
    "            cv2.imwrite(save_dir,img)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3dbac9",
   "metadata": {},
   "source": [
    "## Convert segmentation mask to bounding box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8fee22e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dgyawa1\\Desktop\\dev\\lib\\site-packages\\torchvision\\io\\image.py:11: UserWarning: Failed to load image Python extension: [WinError 126] The specified module could not be found\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchvision.transforms.functional as F\n",
    "\n",
    "\n",
    "ASSETS_DIRECTORY = \"assets\"\n",
    "\n",
    "plt.rcParams[\"savefig.bbox\"] = \"tight\"\n",
    "\n",
    "\n",
    "def show(imgs):\n",
    "    if not isinstance(imgs, list):\n",
    "        imgs = [imgs]\n",
    "    fix, axs = plt.subplots(ncols=len(imgs), squeeze=False)\n",
    "    for i, img in enumerate(imgs):\n",
    "        img = img.detach()\n",
    "        img = F.to_pil_image(img)\n",
    "        axs[0, i].imshow(np.asarray(img))\n",
    "        axs[0, i].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "67a7c8ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "No such operator image::read_file",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1472\\1835088382.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mimg_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mr\"C:\\Users\\dgyawa1\\Downloads\\FoodSeg103\\FoodSeg103\\Images\\img_dir\\train\\00000000.jpg\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\dev\\lib\\site-packages\\torchvision\\io\\image.py\u001b[0m in \u001b[0;36mread_image\u001b[1;34m(path, mode)\u001b[0m\n\u001b[0;32m    220\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mimage_channels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_height\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_width\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m     \"\"\"\n\u001b[1;32m--> 222\u001b[1;33m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdecode_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\dev\\lib\\site-packages\\torchvision\\io\\image.py\u001b[0m in \u001b[0;36mread_file\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \"\"\"\n\u001b[1;32m---> 42\u001b[1;33m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\dev\\lib\\site-packages\\torch\\_ops.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, op_name)\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[1;31m# for overloads and raise an exception if there are more than one.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[0mqualified_op_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'{}::{}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m         \u001b[0mop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_get_operation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mqualified_op_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m         \u001b[1;31m# let the script frontend know that op is identical to the builtin op\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[1;31m# with qualified_op_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: No such operator image::read_file"
     ]
    }
   ],
   "source": [
    "from torchvision.io import read_image\n",
    "\n",
    "mask_path = r\"C:\\Users\\dgyawa1\\Downloads\\FoodSeg103\\FoodSeg103\\Images\\ann_dir\\train\\00000000.jpg\"\n",
    "img_path = r\"C:\\Users\\dgyawa1\\Downloads\\FoodSeg103\\FoodSeg103\\Images\\img_dir\\train\\00000000.jpg\"\n",
    "\n",
    "img = read_image(img_path)\n",
    "mask = read_image(mask_path)\n",
    "\n",
    "print(mask.size())\n",
    "print(img.size())\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915ba54c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
