{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "078bb601-6aef-4d28-a692-aaf84191a20c",
   "metadata": {},
   "source": [
    "### Install detectron2\n",
    "\n",
    "We are using detectron2 library for training and evaluation. Detectron2 consists of mask-rcnn algorithms for image segmentation and various pre-trained models which can be used to train the models by tweaking some of the parameters. Detectron betters works on GPU and need to install pytorch to run on the machine. It is recommeded to install Cuda, Cudnn, pytorch and opencv for better training and inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba42660d-54f1-4175-9324-fe9942249080",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b7ce45-d0a9-49bc-a2e3-63eea22bbb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determining the path required for dataset/\n",
    "\n",
    "class Paths:\n",
    "    DATASET_DIR = \"dataset\"\n",
    "    TRAIN_IMAGES_DIR = f\"{DATASET_DIR}/train/images\"\n",
    "    TRAIN_ANNOTATIONS = f\"{DATASET_DIR}/train/annotations.json\"\n",
    "    VALID_IMAGES_DIR = f\"{DATASET_DIR}/val/images\"\n",
    "    VALID_ANNOTATIONS = f\"{DATASET_DIR}/val/annotations.json\"\n",
    "\n",
    "\n",
    "class DatasetLabels:\n",
    "    TRAIN = \"dataset_train\"\n",
    "    VAL = \"dataset_val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695882f9-a788-4d61-9710-d9bd8e84e472",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from multiprocessing import Pool\n",
    "from collections import Counter\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "from loguru import logger\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from pycocotools.coco import COCO\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from detectron2.data.datasets import register_coco_instances, register_coco_panoptic\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.utils.visualizer import ColorMode\n",
    "from detectron2.data import MetadataCatalog\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.utils.events import get_event_storage\n",
    "from detectron2.engine import HookBase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29332b3-463d-45c4-9df1-716ffa2dd8c8",
   "metadata": {},
   "source": [
    "### Visualize the dataset\n",
    "It is extremely important to visualize the dataset before feeding it into the model. I have used COCOEvalutor to visualize the data. All the annotations are present in COCO format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a4fe05-cdb5-45a8-8cc7-457d94ee4262",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO\n",
    "import numpy as np\n",
    "import skimage.io as io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703e949a-fcbd-4718-b710-78d8d226167a",
   "metadata": {},
   "outputs": [],
   "source": [
    "coco = COCO(Paths.VALID_ANNOTATIONS)\n",
    "catIDs = coco.getCatIds()\n",
    "cats = coco.loadCats(catIDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e77060-fedc-4e94-bdc5-bff666903c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"\"]\n",
    "catIds = coco.getCatIds(catNms=labels)\n",
    "imgIds = coco.getImgIds(catIds)\n",
    "print(\"Total images:\",len(imgIds))\n",
    "print(imgIds[np.random.randint(0,len(imgIds))])\n",
    "imgs = coco.loadImgs(imgIds[np.random.randint(0,len(imgIds))])[0]\n",
    "img_filename = imgs.get(\"file_name\")\n",
    "I = io.imread(os.path.join(Paths.VALID_IMAGES_DIR,img_filename))/255\n",
    "plt.imshow(I)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e90caa-ed9a-421d-b005-bc4cda6f4800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and display instance annotations\n",
    "plt.imshow(I)\n",
    "plt.axis('off')\n",
    "annIds = coco.getAnnIds(imgIds=imgs['id'], catIds=catIds, iscrowd=None)\n",
    "anns = coco.loadAnns(annIds)\n",
    "coco.showAnns(anns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27215c2-4128-4c4e-bbdd-b0178872ab56",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(Paths.TRAIN_ANNOTATIONS) as fp:\n",
    "    dest_train_annotations = json.load(fp)\n",
    "with open(Paths.VALID_ANNOTATIONS) as fp:\n",
    "    dest_valid_annotations = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3b1ed0-d254-472e-94a1-19f9e9863474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detectron2 requires the dataset to be registered in their instances before feeding into the network\n",
    "\n",
    "_ = setup_logger()\n",
    "\n",
    "register_coco_instances(DatasetLabels.TRAIN, {}, Paths.TRAIN_ANNOTATIONS, Paths.TRAIN_IMAGES_DIR)\n",
    "register_coco_instances(DatasetLabels.VAL, {}, Paths.VALID_ANNOTATIONS, Paths.VALID_IMAGES_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a36308-7f55-485e-9f2a-eda7084c2de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the configuration for training\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (DatasetLabels.TRAIN,)\n",
    "cfg.DATASETS.TEST = ()\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 8 # Number of output classes\n",
    "\n",
    "cfg.OUTPUT_DIR = \"outputs\"\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml\")\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad36170-7f4f-43e6-9fe5-5b137ef4e75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.SOLVER.BASE_LR = 0.00025  # Learning Rate\n",
    "cfg.SOLVER.MAX_ITER = 30000  # MAx Iterations\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128  # Batch Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe76baf-e9c1-40af-b945-563f2b9b0437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training\n",
    "trainer = DefaultTrainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e83cac-c264-4997-b0c9-c36b42d5243e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up trained models for evaluation\n",
    "\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "cfg.DATASETS.TEST = (DatasetLabels.VAL, )\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f53244-6204-44c8-a43b-69a6638d2089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the trained model quantitatively\n",
    "\n",
    "evaluator = COCOEvaluator(DatasetLabels.VAL, cfg, False, output_dir=cfg.OUTPUT_DIR)\n",
    "data_loader = build_detection_test_loader(cfg, DatasetLabels.VAL)\n",
    "results = inference_on_dataset(predictor.model, data_loader, evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf70a034-7f0f-4b87-8be2-1357b127338c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the model quantitatively\n",
    "\n",
    "test_img_path = \"008220.jpg\"  # Need to add the path for images\n",
    "test_img = cv2.imread(test_img_path)\n",
    "predictions = predictor(test_img)\n",
    "v = Visualizer(test_img[:, :, ::-1],\n",
    "    scale=0.5, \n",
    "      )\n",
    "annotated_image = v.draw_instance_predictions(predictions[\"instances\"].to(\"cpu\"))\n",
    "plt.imshow(annotated_image.get_image())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
